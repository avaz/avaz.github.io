<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.20">
<title>Anderson Duarte Vaz</title>
<link rel="stylesheet" href="./asciidoctor.css">
</head>
<body class="article">
<div id="header">
<h1>Anderson Duarte Vaz</h1>
</div>
<div id="content">
<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p><span class="image left"><img src="avatar-head-no-bg.png" alt="Avatar" width="300" height="300"></span></p>
</div>
<table class="tableblock frame-none grid-none stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Head of Data and Engineering</strong><br>
<em>Amsterdam Area, Netherlands</em><br></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Email</strong>: <a href="mailto:dev@andersonvaz.com">dev@andersonvaz.com</a><br>
<strong>Linkedin</strong>: <a href="https://www.linkedin.com/in/andersonvaz/" class="bare">https://www.linkedin.com/in/andersonvaz/</a><br>
<strong>Github</strong>: <a href="https://github.com/avaz" class="bare">https://github.com/avaz</a></p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>Hands-on Software Engineer with 17+ years of experience out of 8+ years in management leading teams 20+ software and machine learning engineers. Recently, I&#8217;ve been focusing on data engineering for machine learning projects, specifically in the area of Data Architectures with focus on MLOps and machine learning productization. I hold a major in Computer Sciences and a Master in Business Administration.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_skills">Skills</h2>
<div class="sectionbody">
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Behavioral</th>
<th class="tableblock halign-left valign-top">Technical</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">👨🏽‍💻Very hands-on professional, capable of designing and implementing software solutions applying the most variety of standards, architectures, SAAS and technologies mainly with Java, Python and Javascript focusing in distributed systems and data engineering for machine learning and model operations and customization.</p>
<p class="tableblock">👨🏻‍🏫 Lead and mentor a team of software engineers, fostering a collaborative and innovative work environment. Provide technical guidance and expertise to the team, keeping up to date with the latest industry trends and best practices.</p>
<p class="tableblock">👀 Oversee the design, development, and maintenance of software solutions, with a strong focus on Java, Python, Javascript and Machine Learning.</p>
<p class="tableblock">📈 Manage software development projects from concept to deployment, ensuring timely delivery and quality. Effectively manage resources, and timelines to meet project objectives.</p>
<p class="tableblock">👩🏻‍🤝‍👩🏼🧑‍🤝‍🧑👩🏽‍🤝‍👨🏾Can easily get along together with cross-functional teams of a diverse set of skills like software and machine learning engineers, data scientists, product managers, executive stakeholders, to align efforts with company goals.</p>
<p class="tableblock">🗣️ Strong communication skills in written and verbal form being able to deal with internal and external stakeholders to provide updates, gather requirements, and address any technical concerns.</p>
<p class="tableblock">🧠 Entrepreneurship mindset, proven track of making business thrive through software with solid problem solving skills.</p>
<p class="tableblock">🚅 Defining and driving the organization&#8217;s technology strategy and roadmap.</p>
<p class="tableblock">🧑🏽‍🎓 Hold a Major in Computer Science, a Master’s in Business Administration, and a comprehensive set of industry technology certifications and specializations.</p>
<p class="tableblock">🫶🏽 Lover and in favor of old but not even a bit afraid in try the new. Technologies and paradigms are enjoyable things to deal with.</p>
<p class="tableblock">📚 Values good practices, design patterns, and clean code. Solid knowledge in a wide set of programming languages, frameworks, tools, and technologies in general.</p>
<p class="tableblock">♻️ Contributor and stronger supporter of open source software.</p>
<p class="tableblock">👾 Skilled video-game player, CoD mobile is the one most played at the moment.</p>
<p class="tableblock">🫐 Açaí addicted, best fruit in the world.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Java</strong>: Core, JPA/Hibernate/QueryDSL, JDBC, Bean Validation, NIO, Streams, Executor Service/Concurrency.
I&#8217;m well-versed in the Spring framework and its various modules, such as Spring Boot, MVC, Security, Kafka, Camel, Data, Cloud, Rest Docs and others.
Other relevant libraries/frameworks Flyway, Jackson/Custom De/Serializers/View Groups, Gradle, and Maven.</p>
<p class="tableblock"><strong>Python</strong>: I have focused on Python for the last 6 years. I work with libraries such as pathlib, os, pandas, numpy, scikit-learn, scipy, PySpark, Keras, PyTorch, Pydantic, Spotify Luigi, BeautifulSoup4, SQLAlchemy, FastAPI, setuptools, poetry, and requirements.txt. I also have experience with Pyenv/Virtualenv and (mini)conda.</p>
<p class="tableblock"><strong>Front End</strong>: JavaScript, Node.js/npm, Vue.js v2/3, Nuxt.js v3. Additionally, HTML, CSS/Tailwind CSS, Storyblok CMS, and Strapi CMS. I have a good understanding of the Node.js and JavaScript ecosystem and can do front-end development.</p>
<p class="tableblock"><strong>Architectural Styles</strong>:
I have experience with microservices, event-driven, and serverless architectures.
Of course, I have created monolith applications and have experience with the strangler pattern.</p>
<p class="tableblock"><strong>Integration</strong>: Apache Camel, CXF, web/HTTP/ReST APIs.</p>
<p class="tableblock"><strong>Data Engineering</strong>: Batch, streaming, data pipelines, and data lakes, Databricks lakehouse (medallion pattern), data warehouses and data modeling.</p>
<p class="tableblock"><strong>Business Intelligence</strong>: Databricks Visualization support, Tableu, Hex, Evidence, Apache Superset.</p>
<p class="tableblock"><strong>Storage/Databases/Cache</strong>: I have solid knowledge of SQL, which helps me when working with various persistence technologies. I&#8217;ve used MySQL, PostgreSQL, SQLite, MongoDB, Hive, Pig, Hadoop, Memcache, Redis, DuckDB, and vector databases such as Milvus.</p>
<p class="tableblock"><strong>Analytics</strong>: I have an understanding of MapReduce, CDC concepts, ETL, data ingestion, cleaning, wrangling, transformation, analytics, and reporting/BI. I&#8217;ve worked with Apache Kafka/KSQLDB, (py)Spark, and Delta Lake. Additionally, I&#8217;m familiar with
statistical analysis techniques.</p>
<p class="tableblock"><strong>DevOps/IaC</strong>: I have experience with GitHub Actions, Jenkins, AWS CDK/CloudFormation, Terraform, Docker, Docker Compose, and Kubernetes.</p>
<p class="tableblock"><strong>MLOps</strong>: Custom MLOps pipelines, Iterative/DVC/TPI, MLflow, Ray.io, AWS SageMaker, and Databricks MLflow.</p>
<p class="tableblock"><strong>Infrastructure/Cloud</strong>: I&#8217;m most experienced with AWS and have run several production workloads with autoscale support, following the Well-Architected Framework, also, I know managed services like AWS Glue, Redshift, AppFlow, Lambda, SNS, SQS, S3, ECS, EC2(GPU), Aurora/RDS, CodeCommit/Deploy. I know very well Google Cloud and services like BigQuery, Cloud Storage, Cloud Spanner, and Cloud Functions, Monitoring, Compute. On Azure I have basic knowledge of services like Azure Functions, Azure Storage, Azure SQL, Azure DevOps, and Azure Kubernetes Service. I have knowledge with monitoring and logging tools like AWS CloudWatch, Google Cloud Monitoring, Grafana, and Prometheus.</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect1">
<h2 id="_recent_projects">Recent projects:</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>Quality Estimation API (<a href="https://api.taus.net" class="bare">https://api.taus.net</a>), an application that accurately estimates the quality of machine translation output. The API is built using Python, FastAPI, Pydantic, PySpark, and PyTorch. The API is deployed on AWS EC2 GPU/cuda instances with Spring Cloud Gateway and Memached for caching. The API is deployed using Docker and GitHub Actions. Also, a full MLOps pipeline is in place for training and deploying new models, using PyTorch, Iterative/DVC/TPI, AWS S3/Lambdas.&#8201;&#8212;&#8201;TAUS 2023</p>
</li>
<li>
<p>Revamped the TAUS website (<a href="https://taus.net" class="bare">https://taus.net</a>), replaced Joomla with using Nuxt.js v3, Tailwind CSS, and Storyblok CMS. Joomla is great and a nice CMS but we had just one person in the company who knew how to work with it, with the revamp we have a much more flexible and modern website that is straightforward to maintain and update by anyone in the company. The website is deployed on AWS ECS using Docker and GitHub Actions. This application also integrates with other microservices for authentication and authorization and user management.&#8201;&#8212;&#8201;TAUS 2022</p>
</li>
<li>
<p>TAUS Data Marketplace (<a href="https://datamarketplace.taus.net" class="bare">https://datamarketplace.taus.net</a>), a marketplace for language data. The marketplace is built using Java 17, Spring Boot/MVC/Security/Kafka/Data, JPA/Hibernate, QueryDSL, Jackson, Flyway, Gradle, AWS RDS MySQL. The marketplace is deployed on AWS ECS using Docker and GitHub Actions with OpenId Connect authorization.&#8201;&#8212;&#8201;TAUS 2022</p>
</li>
<li>
<p>A serverless Data architecture for data processing and analytics. The architecture is built using Spring Camel, Apache Camel, QueryDSL/SQL, AWS Lambda/S3/Aurora/SNS/SQS/ECS, to AWS ECS using GitHub Actions. The data processing starts by uploading a file to S3 which triggers a lambda function that checks if there is enough AWS ECS Tasks available (rate limiting) to process the file, if not it triggers a new task otherwise forwards the message to a SQS queue which later will be consumed by the task. The task once completed sends a notifications to SNS where other components (ECS Tasks) will consume the message and process the data. Errors are sent to a SQS DLQ for further investigation.&#8201;&#8212;&#8201;TAUS 2021</p>
</li>
<li>
<p>A machine learning pipeline to train and inference a model to predict the amount of baking articles that should be baked for one of Europe&#8217;s biggest retail supermarket companies. The pipeline is built using Python, PySpark, Numpy, Pandas, Jinja, Apache Hadoop/pySpark, Hive and Spotify Luigi.&#8201;&#8212;&#8201;Teradata/LiDL 2019/2020</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_professional_experience">Professional Experience</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_taus_httpstaus_net">TAUS - <a href="https://taus.net" class="bare">https://taus.net</a></h3>
<div class="paragraph">
<div class="title">Head of Data and Engineering, March 2020 - Present, Amsterdam, The Netherlands</div>
<p>At TAUS, I’m in charge of the whole engineering and data teams, I oversee everything that is created and align our technologies with the business goals. But what this really means is that I’m one of the actual doers, I don’t just communicate and explain the need, but I also design and help to shape how it will look like technically speaking, a very hands-on position and attitude. I’m responsible for designing and implementing most of our core Data Architecture entirely based on serverless pipelines. I’m the head of a multidisciplinary and multipolyglot teams made of back and front enders and machine learning engineers with strong focus in NLP, working in different fronts that come together delivering production-ready products.
Initially, I started as Principal Software Engineer with the responsibility to realize the Data Marketplace project, an EU funded project. Soon after delivering this project, I engaged in creating what is now the main data architecture in the company.
With that I moved as Head of Data and Engineering in this position, I assembled teams to deliver all sorts of projects, including a complete digital transformation by deploying a set a new tools and processes, and recently the creation of a new product for the translation industry, TAUS Quality Estimate API. Some of these projects I helped to design and implement myself, others I led the team that did it, and others I was the one that implemented it. I focus in makes sure that projects are delivered on time and with the expected quality.</p>
</div>
<div class="sect3">
<h4 id="_projects">Projects</h4>
<div class="sect4">
<h5 id="_quality_estimate_api">Quality Estimate API</h5>
<div class="paragraph">
<p>Designed Machine Learning operations workflow where machine learning engineers can train models using GPUs or CPUs in a cost-effective manner using tools that favours serverless and affordable infrastructure machine instances, with support for job save and resuming and knowledge sharing among the team members. This greatly improves our Machine Learning/NLP researching projects and operations.</p>
</div>
<div class="paragraph">
<p>Architected and implemented TAUS Quality Estimate API which process 50mi+ characters daily.
The solution offers metrics scoring that evaluates how good is a machine translation.
This is the company&#8217;s flagship product with used by big tech customers in ride-sharing and transportation network industry, fraud prevention services, LSP&#8217;s and others.
It&#8217;s an HTTP API with a MLOps workflow, developed using Python, PyTorch, Poetry, AWS EC2+GPU.</p>
</div>
<div class="paragraph">
<div class="title">Attributions:</div>
<p>I was responsible for the whole development of the API from scratch, excluding the Machine Learning model training. However, I implemented the whole model management process and the API to serve the model.</p>
</div>
<div class="paragraph">
<div class="title">Techs:</div>
<p>Python, FastAPI, AWS ECS, EC2(GPU), S3, Lambda, Docker, GitHub, GitHub Actions, Python Poetry.</p>
</div>
</div>
<div class="sect4">
<h5 id="_data_marketplace">Data Marketplace</h5>
<div class="paragraph">
<p><a href="https://datamarketplace.taus.net/" class="bare">https://datamarketplace.taus.net/</a></p>
</div>
<div class="paragraph">
<p>An e-commerce platform to allow trading Language Data i.e., translations.
The platform allows publishing language data for sale,
define the price and additional metadata like domain and content-type.
The platform also allows the user to buy data from other users.
The platform is integrated with a payment gateway
to allow the user to pay for the data and be paid when their data is sold.</p>
</div>
<div class="paragraph">
<div class="title">Attributions:</div>
<p>I created the platform from scratch.
I developed it in a window of 5 months together with another developer.
Out of this project was created the Data Language Architecture which currently is the main data architecture for the company.</p>
</div>
<div class="paragraph">
<div class="title">Techs:</div>
<p>Java, Spring Framework/MVC/Data/Kafka/Cloud/Security, JPA, VueJS, AWS RDS, SNS, SQS, S3, Lambda, Stripe, Docker, Github, Github Actions, Gradle.</p>
</div>
</div>
<div class="sect4">
<h5 id="_data_language_architecture">Data Language Architecture</h5>
<div class="paragraph">
<p>A platform to allow ingestion, processing, and cleaning of Language Data (i.e., translations).
The set of components that compose the platform comprises the core of the company&#8217;s data architecture.
Giving the nature of the data ingestion at TAUS was decided to take a serveless approach to the architecture.
A file is uploaded to S3
and a Lambda function is triggered which in turn check if up to certain threshold ECS tasks are running,
if it is the lambda just forward the file information to a SQS queue which will be processed by the ECS task, if not the lambda will start a new ECS task to process the file and forward the message to the SQS queue.
This is because files tend to be big and a strict clean process is needed to be applied to the data,
which takes time and would exceed the 15-minutes limit of a lambda function.</p>
</div>
<div class="paragraph">
<div class="title">Attributions:</div>
<p>I implemented the whole architecture from scratch
providing at the end a standard way to do data ingestion and an API to consume the data ingested.</p>
</div>
<div class="paragraph">
<div class="title">Techs:</div>
<p>Java, Spring, QueryDSL/SQL, Apache Camel, AWS Aurora, SNS, SQS, S3, Lambda, Docker, Github, Github Actions, Gradle.</p>
</div>
</div>
<div class="sect4">
<h5 id="_digital_transformation">Digital Transformation</h5>
<div class="paragraph">
<p>The situation was the following, <a href="https://www.taus.net" class="bare">https://www.taus.net</a>;
the main company website was hosted by Joomla, an exceptional CMS platform.
However, there was only one person in the company maintaining it and the engineer was not so happy with that.
All the other engineers were working with Java and modern NodeJS frameworks.
This wasn&#8217;t interesting to anybody involved in this situation.
After a thoughtful analysis, I made a plan, assembled a team of four people, two juniors, one senior, and I, and we moved on to create a new website with a new technology stack.
The senior engineer was responsible for the backend, which included migrating user base from Joomla to a new database and also provides an API for authentication and corporate data.
The mid-seniors were responsible for the frontend and integrate with the new chosen CMS (Storyblok). A senior engineer and I were responsible to create what we called Corporate API service which holds user, products, and other corporate data provided to the website and all other company products.
In 2 development cycles (12 weeks) we were up and running with the website
that is live to this day (<a href="https://www.taus.net" class="bare">https://www.taus.net</a>),
with support for product checkout integrated with several payment brokers, our CRM (HubSpot) offering a multitude of corporate services.
Giving the component-based approach taken to build the website, currently,
business people can create new pages and components without the need for an engineer to help them.
A lot of knowledge was transferred, and everyone gained a lot of experience in the process.</p>
</div>
<div class="paragraph">
<div class="title">Attributions:</div>
<p>I helped to define the base architecture, defined the technology stack,
and more importantly, mentored the team to deliver the project.</p>
</div>
<div class="paragraph">
<div class="title">Techs:</div>
<p>Java, SpringBoot, VueJS/NuxtJS, Storyblok CMS, AWS ECS, ECR, RDS, Docker.</p>
</div>
<div class="sect5">
<h6 id="_other_projects">Other Projects</h6>
<div class="paragraph">
<p>Apart from the projects mentioned above, I was also involved in several other projects executed by several teams with attributions that range from specification definition, design, QA, and development.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_teradata_httpswww_teradata_com">Teradata - <a href="https://www.teradata.com" class="bare">https://www.teradata.com</a></h3>
<div class="paragraph">
<div class="title">Lead Software Engineer, November 2017 - March 2020 - Amsterdam, The Netherlands</div>
<p>Responsible to help customer to succeed on BigData and Artificial Intelligence (Deep Learning) projects.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Architect and deploy BigData projects based on Hadoop with orchestration and ingestion done by Luigi, Airflow or Kylo/NiFi and consumption with Kafka, Spark and others.</p>
</li>
<li>
<p>Architect 'AnalyticsOps' workflows which automate the process of test, train, deploy and 'champion/challenge' of machine learning models for a considerable amount of different tools and frameworks like, SparkML, SciKitLearn, TensorFlow/Keras, PyTorch with model deployment of type K5, ONNX, PMML.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Significant projects:
Working as a Senior Data Engineer for one of the world’s largest retailers in creating a platform to generate forecast for reducing waste in baked goods using Machine Learning and numerical optimization. Executed live A/B test in a European country with &gt;500 stores for 6 months and reached 15% waste reduction and increased revenue. Solution has been rolled out in several countries and shall finally be used in &gt;30 countries (&gt;10k stores). The data pipeline for this project processed around 3TB of information.</p>
</div>
<div class="paragraph">
<p>Technology stack includes: Python, PySpark, Hadoop, Hive, PyTorch, ScikitLearn.</p>
</div>
<div class="paragraph">
<p>For one of the biggest Spain banks helped in create an end-to-end solution to streamlined paper forms such as tax submissions, mortgages, loans, etc. The platform receives the scanned document, recognise its the type through machine learning image recognition models, split it apart in different sub images, apply OCR to gather the text and by using other machine learning models it identifies things like ticked check boxes, afterward with all the information captured send it to the proper Bank system for further processing. This project led to significant savings in money and time for the Bank by a significant decrease in manual and error-prone processing. I worked on the MLOps part of the project.</p>
</div>
<div class="paragraph">
<p>Technology stack includes: Python, PySpark, Hadoop, Hive, PyTorch, ScikitLearn.</p>
</div>
</div>
<div class="sect2">
<h3 id="_backbase_httpswww_backbase_com">Backbase - <a href="https://www.backbase.com" class="bare">https://www.backbase.com</a></h3>
<div class="paragraph">
<div class="title">Chapter Lead/Senior Software Engineer, June 2016 - September 2017 (1 year 4 months), Amsterdam Area, Netherlands</div>
<p>Responsible for lead teams to develop and deploy Backbase Portal projects to customers all over the world. Talk directly to senior management and architects to understand the requirements and implement those in the product. Also act as a trainer and interact with the RnD department to help enhance Backbase product as a whole.</p>
</div>
<div class="paragraph">
<p>From Backbase CXP version 5.x to 6.x the underline architecture changed from monolith to microservices, I helped with this process by creating a library that would allow the version 5.x of the product to be deployed in a microservices architecture.</p>
</div>
<div class="paragraph">
<p>Engaged in several successful pre-sales efforts which led to big contracts for the company.</p>
</div>
<div class="paragraph">
<p>Some of the projects that I helped with include:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Banamex, Mexico: I led a complete revamp of Banamex&#8217;s customer onboarding experience.</p>
</li>
<li>
<p>MetroBank, London: I deployed and mentored the MetroBank team in using the Backbase solution.</p>
</li>
<li>
<p>Valiant Bank, Switzerland: I executed a full Backbase project, including implementation, deployment, and production support.</p>
</li>
<li>
<p>CornerBank Group, Switzerland: I provided consultancy and mentoring services.</p>
</li>
<li>
<p>Íslandsbanki, Iceland: Successful Pre-Sales engagement demonstrating how Backbase platform works for key management and executive members of the bank.</p>
</li>
<li>
<p>CIMB Bank, Thailand: Delivered training on Backbase for Bank employees.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_uol_httpswww_uol_com_br">UOL - <a href="https://www.uol.com.br" class="bare">https://www.uol.com.br</a></h3>
<div class="paragraph">
<div class="title">Project Coordinator and Solution Architect, January 2013 - January 2014 (1 year 1 month), São Paulo Area, Brazil</div>
<p>My main responsibilities are to coach teams, design and implement systems, do trainings, suggest and make proof of concept of new frameworks and tools trying to improve overall productivity of the team that I work with.</p>
</div>
<div class="paragraph">
<p><strong>Some of my main accomplishments:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Managed teams simultaneously delegating tasks and coordinating releases of different projects.</p>
</li>
<li>
<p>Resolved the main problem with one of the projects while leading the team with other tasks.</p>
</li>
<li>
<p>Influenced other teams to use new technologies, practices and tools.</p>
</li>
<li>
<p>Negotiated new features to stakeholders.</p>
</li>
<li>
<p>Reduced about ~30% of the operational cost of the revenue assurance department.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_education">Education</h2>
<div class="sectionbody">
<table class="tableblock frame-none grid-none stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-center valign-top">Student</th>
<th class="tableblock halign-center valign-top">Professor/Instructor</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Master of Business Administration (MBA)</strong><br>
<em>Fundação Getúlio Vargas São Paulo<br>
2010 - 2011</em><br>
<a href="https://educacao-executiva.fgv.br/" class="bare">https://educacao-executiva.fgv.br/</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Graduate Studies Professor</strong><br>
<em>Senac São Paulo<br>
2010 - 2011</em><br>
<a href="http://www.sp.senac.br" class="bare">http://www.sp.senac.br</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock"><strong>Bachelor&#8217;s in Computer Sciences</strong><br>
<em>Pontifícia Universidade Católica de São Paulo</em><br>
1999 - 2004<br>
<a href="https://www.pucsp.br/graduacao/ciencia-da-computacao" class="bare">https://www.pucsp.br/graduacao/ciencia-da-computacao</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Java and Middleware Certified Instructor</strong><br>
<em>Oracle Brazil</em><br>
2008 - Present*<br>
<a href="https://education.oracle.com/java/java/pFamily_48" class="bare">https://education.oracle.com/java/java/pFamily_48</a><br>
* <em>I&#8217;m living in the Netherlands, back in Brazil I&#8217;m still an Oracle instructor</em></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Java/SAP ABAP Certified Instructor</strong><br>
<em>SAP</em><br>
2004 - 2008<br>
<a href="https://www.sap.com" class="bare">https://www.sap.com</a></p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect1">
<h2 id="_specializations">Specializations</h2>
<div class="sectionbody">
<table class="tableblock frame-none grid-none stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-center valign-top">Certifications/Accreditations</th>
<th class="tableblock halign-center valign-top">Courses</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>AWS Certified Cloud Practitioner</strong><br>
<a href="https://www.credly.com/badges/6e80c9f1-6eaa-4ac2-b4c1-6b070b6207c7" class="bare">https://www.credly.com/badges/6e80c9f1-6eaa-4ac2-b4c1-6b070b6207c7</a><br></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Get Started with Machine Learning on Databricks<br>
Get Started with Data Engineering on Databricks<br>
Data Workloads with Repos and Workflows on Databricks<br>
Data Analytics and Warehousing with Databricks SQL<br>
Data Storage and Management with Delta Lake<br>
Data Governance with Unity Catalog<br>
Data Pipelines with Delta Live Tables<br>
Generative AI Fundamentals<br>
Streaming with Structured Streaming and Delta Live Tables</strong><br>
<em>Databricks Academy</em><br>
<a href="https://customer-academy.databricks.com" class="bare">https://customer-academy.databricks.com</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Databricks - Academy Accreditation - Generative AI Fundamentals</strong><br>
<a href="https://credentials.databricks.com/adb7bbb9-985a-4f99-950b-3814dd9adf2c" class="bare">https://credentials.databricks.com/adb7bbb9-985a-4f99-950b-3814dd9adf2c</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Introduction to Data Engineering</strong><br>
<a href="https://www.coursera.org/account/accomplishments/verify/ZQ2D56H7BFPF" class="bare">https://www.coursera.org/account/accomplishments/verify/ZQ2D56H7BFPF</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Databricks - Academy Accreditation - Lakehouse Fundamentals</strong><br>
<a href="https://credentials.databricks.com/a8fb7f4f-544c-450a-b7ae-94b61f1663e9" class="bare">https://credentials.databricks.com/a8fb7f4f-544c-450a-b7ae-94b61f1663e9</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Teradata - Intro to Vantage</strong><br>
<a href="https://www.credly.com/badges/68d53e4f-5993-4ddc-88d9-3e29d029dfca/linked_in_profile" class="bare">https://www.credly.com/badges/68d53e4f-5993-4ddc-88d9-3e29d029dfca/linked_in_profile</a><br></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Confluent Fundamentals Accreditation</strong><br>
<a href="https://www.credential.net/ea52a54e-2989-4a91-bcbe-2d1e0d64d144#gs.4q45ly" class="bare">https://www.credential.net/ea52a54e-2989-4a91-bcbe-2d1e0d64d144#gs.4q45ly</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Hadoop Operations: Hadoop Administration Foundation</strong> -
<em>Hortonworks/Teradata, 2018</em></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Certified Web Components for Java Platform<br>
Certified Programmer for Java Platform<br>
Certified Associate for Java Platform</strong><br>
<em>Oracle (former Sun) University, 2006</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>MongoDB Aggregation Framework (M121)</strong><br>
<strong>MongoDB for DBAs (M102)</strong><br>
<strong>MongoDB for Java Developers (M101J)</strong><br>
<em>Mongo University, 2016</em></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>SAP Certified Instructor for SAP Technologies<br>
SAP Netweaver Workbench for ABAP +</strong>
<em>SAP University and Instructors Program, 2008</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>COBIT - Auditing IT Systems</strong><br>
<em>Galegale &amp; Associates, 2011</em></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>ReST from Scratch (by Guilherme Silveira)<br>
Continuous Delivery (by Martin Fowler and Jez Humble)</strong><br>
<em>QCon Conference Workshops, 2010</em></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Web Application Security Training</strong><br>
<em>Bonsai Information Security, 2010</em></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Introduction to TCP/IP Architecture</strong><br>
<em>Telefonica Brazil, 2006</em></p></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</body>
</html>